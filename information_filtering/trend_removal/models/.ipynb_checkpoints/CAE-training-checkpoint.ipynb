{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4951ac0e-4f7b-4c6d-87e8-fa212d1750a9",
   "metadata": {
    "id": "4951ac0e-4f7b-4c6d-87e8-fa212d1750a9"
   },
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "This notebook uses a **Convolutional Autoencoder**, which is a neural network designed to compress spatial data like maps into a lower-dimensional **latent space**, and then reconstruct it. \n",
    "\n",
    "In our case, the goal is to learn compact representations of the oceanographic maps while preserving important spatial patterns. This helps reduce noise, ignore missing or irrelevant regions (thanks to the masking), and makes it easier to apply further analysis — for example, clustering similar patterns in the compressed space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2f90b1-6826-4a2b-896b-f0f59aa9999c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110274,
     "status": "ok",
     "timestamp": 1750955287591,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "4b2f90b1-6826-4a2b-896b-f0f59aa9999c",
    "outputId": "4dec4adf-f65f-4eea-9962-5fa5887df0ec"
   },
   "outputs": [],
   "source": [
    "!pip install -q -r ../../requirements.txt &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9a3b7-de75-47f5-8e47-612a35397ee0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3c815e-a7d9-46d6-a45d-c64b8ed20a69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1750955461797,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "7e3c815e-a7d9-46d6-a45d-c64b8ed20a69",
    "outputId": "c8c3bc6e-81b3-473b-e58c-d53fa46ceb8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_functions' from '/home/jovyan/spatiotemporal-mining-medsea/information_filtering/trend_removal/models/../../helper_functions.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import helper_functions\n",
    "import importlib\n",
    "importlib.reload(helper_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7cb91c-8458-401b-9d69-1858f6be5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 27\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10a58f-d84f-4be4-abeb-478f20b1b76f",
   "metadata": {},
   "source": [
    "Since our ConvNet works with masked map data, it naturally produces some NaNs — that's expected behavior. To avoid flooding the output with warnings, we've disabled them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2175a-a4a6-4443-89a4-c30147743c2e",
   "metadata": {
    "id": "cec2175a-a4a6-4443-89a4-c30147743c2e"
   },
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c45eb1-fe33-437d-bb7b-91c8b1a76a99",
   "metadata": {
    "executionInfo": {
     "elapsed": 2945,
     "status": "ok",
     "timestamp": 1750955304911,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "25c45eb1-fe33-437d-bb7b-91c8b1a76a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20554.545012 MB\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(\"/home/jovyan/spatiotemporal-mining-medsea/data/medsea.nc\")\n",
    "print(ds.nbytes / 1e6, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe1213c-9dee-4d4e-91d3-012c3db1899c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92667,
     "status": "ok",
     "timestamp": 1750955397579,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "ffe1213c-9dee-4d4e-91d3-012c3db1899c",
    "outputId": "5e8a58d3-c8db-4111-ec0e-9396fe41a514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([342, 6, 203, 514])\n"
     ]
    }
   ],
   "source": [
    "X_np, M_np = helper_functions.preprocessing_conv(ds, [\"thetao\", \"so\"], [50, 300, 1000], False, 1)\n",
    "X = torch.tensor(X_np)  # (B, C, H, W)\n",
    "M = torch.tensor(M_np)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4956a2-917d-4d60-afc2-410b41767582",
   "metadata": {},
   "source": [
    "Again, we include all depths and features for reconstruction. The difference in our ConvNet is that these features are not simply concatenated, but stacked as channels — similar to how RGB channels work in images. This allows the network to capture spatial relationships between features and depths more effectively, which might be important in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11779e19-1403-4924-b480-f5457daaee2e",
   "metadata": {
    "id": "11779e19-1403-4924-b480-f5457daaee2e"
   },
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974f3cdc-1c88-4f71-88ee-bb7d3fe13362",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1750955397581,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "974f3cdc-1c88-4f71-88ee-bb7d3fe13362"
   },
   "outputs": [],
   "source": [
    "class MaskedDataset(Dataset):\n",
    "    def __init__(self, X, M):\n",
    "        self.X = X\n",
    "        self.M = M\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.M[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36cff7de-fbe6-4edb-9c94-5fead6c7a13a",
   "metadata": {
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1750955398447,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "36cff7de-fbe6-4edb-9c94-5fead6c7a13a"
   },
   "outputs": [],
   "source": [
    "full_dataset = MaskedDataset(X_np, M_np)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(val_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed51ed5-9af0-42ad-a1a9-9d9b0b5edfe7",
   "metadata": {
    "id": "4ed51ed5-9af0-42ad-a1a9-9d9b0b5edfe7"
   },
   "source": [
    "## The Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BmPchZzRmXID",
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1750955534808,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "BmPchZzRmXID"
   },
   "outputs": [],
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self, in_channels, latent_dim=3, dropout_p=0.2, channels=[32, 64, 128], input_shape=(203, 514)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.channels = channels\n",
    "\n",
    "        encoder_layers = []\n",
    "        prev_channels = in_channels\n",
    "        h, w = input_shape\n",
    "\n",
    "        for ch in channels:\n",
    "            encoder_layers += [\n",
    "                nn.Conv2d(prev_channels, ch, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(ch),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout2d(p=dropout_p),\n",
    "            ]\n",
    "            prev_channels = ch\n",
    "            h = math.floor((h + 2 * 1 - 3) / 2 + 1)  # Conv2d output size formula\n",
    "            w = math.floor((w + 2 * 1 - 3) / 2 + 1)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.unflatten_shape = (channels[-1], h, w)\n",
    "\n",
    "        flat_dim = channels[-1] * h * w\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_enc = nn.Sequential(\n",
    "            nn.Linear(flat_dim, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(64, latent_dim)\n",
    "        )\n",
    "        self.fc_dec = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(64, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(1024, flat_dim)\n",
    "        )\n",
    "\n",
    "        decoder_layers = []\n",
    "        rev_channels = list(reversed(channels))\n",
    "        for i in range(len(rev_channels) - 1):\n",
    "            decoder_layers += [\n",
    "                nn.ConvTranspose2d(rev_channels[i], rev_channels[i + 1], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(rev_channels[i + 1]),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout2d(p=dropout_p),\n",
    "            ]\n",
    "\n",
    "        decoder_layers += [\n",
    "            nn.ConvTranspose2d(rev_channels[-1], in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        ]\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            x = x * mask\n",
    "        x = self.encoder(x)\n",
    "        z = self.fc_enc(self.flatten(x))\n",
    "        x = self.fc_dec(z)\n",
    "        x = x.view(x.size(0), *self.unflatten_shape)\n",
    "        x = self.decoder(x)\n",
    "        return x[:, :, :self.input_shape[0], :self.input_shape[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd997601-9a5d-4a69-a879-fe1c9936e87b",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder\n",
    "\n",
    "We use a simple convolutional autoencoder that compresses the input maps into a small latent vector and reconstructs them back. The encoder reduces spatial resolution through convolutional layers, while the decoder upsamples the data back using transposed convolutions.\n",
    "\n",
    "I experimented with different numbers of layers, kernel sizes, and dropout values. The current setup gave the best trade-off between reconstruction quality and training stability.\n",
    "\n",
    "\n",
    "### Hard Masking\n",
    "- Since many values in the input maps are invalid (e.g. land areas), we apply a **hard mask** before feeding the data into the encoder.\n",
    "- This mask zeroes out irrelevant values, so the model only learns from valid oceanic regions.\n",
    "- During training, the same mask is applied to the loss function to ensure the model is not penalized for errors in masked-out areas.\n",
    "- This is essential for learning robust spatial patterns without being misled by missing or irrelevant data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f29428-7c81-4a80-a415-c051c92d86cd",
   "metadata": {
    "id": "f9f29428-7c81-4a80-a415-c051c92d86cd"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36d7cfa-8d22-41f0-a1b0-fb2c31ac8f5e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750955398551,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "f36d7cfa-8d22-41f0-a1b0-fb2c31ac8f5e"
   },
   "outputs": [],
   "source": [
    "def masked_mse(x_recon, x_true, mask):\n",
    "    loss = ((x_recon - x_true) ** 2) * mask\n",
    "    return loss.sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696eba88-be08-4790-a145-0a3ddeeffaa2",
   "metadata": {
    "id": "696eba88-be08-4790-a145-0a3ddeeffaa2"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8b3e058-34ba-439d-aeda-aa0a21e6dd5e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750955398556,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "c8b3e058-34ba-439d-aeda-aa0a21e6dd5e"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs: int):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        for x, mask in train_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x_recon = model(x, mask=mask)\n",
    "            loss = masked_mse(x_recon, x, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * x.size(0)\n",
    "\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, mask in test_loader:\n",
    "                x = x.to(device)\n",
    "                mask = mask.to(device)\n",
    "                x_recon = model(x, mask=mask)\n",
    "                loss = masked_mse(x_recon, x, mask)\n",
    "                running_val_loss += loss.item() * x.size(0)\n",
    "\n",
    "        val_loss = running_val_loss / len(test_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29feb4-1f80-400e-b1f7-a41f47fcace9",
   "metadata": {
    "id": "bd29feb4-1f80-400e-b1f7-a41f47fcace9"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fecc03-c5a1-49d2-87d0-9b490e8ff0c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750955398545,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "22fecc03-c5a1-49d2-87d0-9b490e8ff0c2"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36mleCQi1wa1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "error",
     "timestamp": 1750955678818,
     "user": {
      "displayName": "Bahne Thiel-Peters",
      "userId": "11084520765208222044"
     },
     "user_tz": -120
    },
    "id": "36mleCQi1wa1",
    "outputId": "618c29cd-1083-48b1-b84a-7a9790043df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAE                                      [1, 6, 203, 514]          --\n",
       "├─Sequential: 1-1                        [1, 1024, 4, 9]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 102, 257]         1,760\n",
       "│    └─InstanceNorm2d: 2-2               [1, 32, 102, 257]         --\n",
       "│    └─LeakyReLU: 2-3                    [1, 32, 102, 257]         --\n",
       "│    └─Dropout2d: 2-4                    [1, 32, 102, 257]         --\n",
       "│    └─Conv2d: 2-5                       [1, 64, 51, 129]          18,496\n",
       "│    └─InstanceNorm2d: 2-6               [1, 64, 51, 129]          --\n",
       "│    └─LeakyReLU: 2-7                    [1, 64, 51, 129]          --\n",
       "│    └─Dropout2d: 2-8                    [1, 64, 51, 129]          --\n",
       "│    └─Conv2d: 2-9                       [1, 128, 26, 65]          73,856\n",
       "│    └─InstanceNorm2d: 2-10              [1, 128, 26, 65]          --\n",
       "│    └─LeakyReLU: 2-11                   [1, 128, 26, 65]          --\n",
       "│    └─Dropout2d: 2-12                   [1, 128, 26, 65]          --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 13, 33]          295,168\n",
       "│    └─InstanceNorm2d: 2-14              [1, 256, 13, 33]          --\n",
       "│    └─LeakyReLU: 2-15                   [1, 256, 13, 33]          --\n",
       "│    └─Dropout2d: 2-16                   [1, 256, 13, 33]          --\n",
       "│    └─Conv2d: 2-17                      [1, 512, 7, 17]           1,180,160\n",
       "│    └─InstanceNorm2d: 2-18              [1, 512, 7, 17]           --\n",
       "│    └─LeakyReLU: 2-19                   [1, 512, 7, 17]           --\n",
       "│    └─Dropout2d: 2-20                   [1, 512, 7, 17]           --\n",
       "│    └─Conv2d: 2-21                      [1, 1024, 4, 9]           4,719,616\n",
       "│    └─InstanceNorm2d: 2-22              [1, 1024, 4, 9]           --\n",
       "│    └─LeakyReLU: 2-23                   [1, 1024, 4, 9]           --\n",
       "│    └─Dropout2d: 2-24                   [1, 1024, 4, 9]           --\n",
       "├─Flatten: 1-2                           [1, 36864]                --\n",
       "├─Sequential: 1-3                        [1, 3]                    --\n",
       "│    └─Linear: 2-25                      [1, 1024]                 37,749,760\n",
       "│    └─LeakyReLU: 2-26                   [1, 1024]                 --\n",
       "│    └─Dropout: 2-27                     [1, 1024]                 --\n",
       "│    └─Linear: 2-28                      [1, 64]                   65,600\n",
       "│    └─LeakyReLU: 2-29                   [1, 64]                   --\n",
       "│    └─Dropout: 2-30                     [1, 64]                   --\n",
       "│    └─Linear: 2-31                      [1, 3]                    195\n",
       "├─Sequential: 1-4                        [1, 36864]                --\n",
       "│    └─Linear: 2-32                      [1, 64]                   256\n",
       "│    └─LeakyReLU: 2-33                   [1, 64]                   --\n",
       "│    └─Dropout: 2-34                     [1, 64]                   --\n",
       "│    └─Linear: 2-35                      [1, 1024]                 66,560\n",
       "│    └─LeakyReLU: 2-36                   [1, 1024]                 --\n",
       "│    └─Dropout: 2-37                     [1, 1024]                 --\n",
       "│    └─Linear: 2-38                      [1, 36864]                37,785,600\n",
       "├─Sequential: 1-5                        [1, 6, 256, 576]          --\n",
       "│    └─ConvTranspose2d: 2-39             [1, 512, 8, 18]           4,719,104\n",
       "│    └─InstanceNorm2d: 2-40              [1, 512, 8, 18]           --\n",
       "│    └─LeakyReLU: 2-41                   [1, 512, 8, 18]           --\n",
       "│    └─Dropout2d: 2-42                   [1, 512, 8, 18]           --\n",
       "│    └─ConvTranspose2d: 2-43             [1, 256, 16, 36]          1,179,904\n",
       "│    └─InstanceNorm2d: 2-44              [1, 256, 16, 36]          --\n",
       "│    └─LeakyReLU: 2-45                   [1, 256, 16, 36]          --\n",
       "│    └─Dropout2d: 2-46                   [1, 256, 16, 36]          --\n",
       "│    └─ConvTranspose2d: 2-47             [1, 128, 32, 72]          295,040\n",
       "│    └─InstanceNorm2d: 2-48              [1, 128, 32, 72]          --\n",
       "│    └─LeakyReLU: 2-49                   [1, 128, 32, 72]          --\n",
       "│    └─Dropout2d: 2-50                   [1, 128, 32, 72]          --\n",
       "│    └─ConvTranspose2d: 2-51             [1, 64, 64, 144]          73,792\n",
       "│    └─InstanceNorm2d: 2-52              [1, 64, 64, 144]          --\n",
       "│    └─LeakyReLU: 2-53                   [1, 64, 64, 144]          --\n",
       "│    └─Dropout2d: 2-54                   [1, 64, 64, 144]          --\n",
       "│    └─ConvTranspose2d: 2-55             [1, 32, 128, 288]         18,464\n",
       "│    └─InstanceNorm2d: 2-56              [1, 32, 128, 288]         --\n",
       "│    └─LeakyReLU: 2-57                   [1, 32, 128, 288]         --\n",
       "│    └─Dropout2d: 2-58                   [1, 32, 128, 288]         --\n",
       "│    └─ConvTranspose2d: 2-59             [1, 6, 256, 576]          1,734\n",
       "==========================================================================================\n",
       "Total params: 88,245,065\n",
       "Trainable params: 88,245,065\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 4.46\n",
       "==========================================================================================\n",
       "Input size (MB): 2.50\n",
       "Forward/backward pass size (MB): 39.15\n",
       "Params size (MB): 352.98\n",
       "Estimated Total Size (MB): 394.63\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CAE(in_channels=X_np.shape[1], latent_dim=3, dropout_p=0.2, channels= [32, 64, 128, 256, 512, 1024]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004)\n",
    "\n",
    "summary(model, input_size=(1, X_np.shape[1], 203, 514))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "PUQ6KPZs2CZL",
   "metadata": {
    "id": "PUQ6KPZs2CZL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/800 | Train Loss: 1.0094 | Val Loss: 0.9697\n",
      "Epoch 20/800 | Train Loss: 0.9872 | Val Loss: 0.9357\n",
      "Epoch 30/800 | Train Loss: 0.8122 | Val Loss: 0.7750\n",
      "Epoch 40/800 | Train Loss: 0.7644 | Val Loss: 0.7414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m800\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m running_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:285\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 800\n",
    "train_losses, val_losses = train(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68549efe-8ccf-4412-a9e6-0868f92d4e68",
   "metadata": {
    "id": "68549efe-8ccf-4412-a9e6-0868f92d4e68"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7c521-adda-4880-a83d-a9a10f780db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.plot_metrics([(train_losses, \"Train Loss\"), (val_losses, \"Validation Loss\")], \"Loss (MSE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0900f0b-2057-4fc5-b583-a0a64b532819",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"CAE.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7749099,
     "sourceId": 12294777,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7749153,
     "sourceId": 12301699,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 387008,
     "modelInstanceId": 366113,
     "sourceId": 451267,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
