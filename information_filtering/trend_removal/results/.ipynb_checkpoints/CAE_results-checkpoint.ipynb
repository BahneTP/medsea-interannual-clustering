{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4951ac0e-4f7b-4c6d-87e8-fa212d1750a9",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n",
    "This notebook makes use of the **Autoencoder**, which is used to reduce the dimensionality of our dataset in a non-linear way. Furthermore, we then apply **k-means Clustering** as in our last notebook in our new created **Latent Space** in lower dimension. We do so, to get rid of less important variables and achieve a better Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2f90b1-6826-4a2b-896b-f0f59aa9999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r ../../requirements.txt &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3c815e-a7d9-46d6-a45d-c64b8ed20a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import helper_functions\n",
    "import importlib\n",
    "importlib.reload(helper_functions)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed51ed5-9af0-42ad-a1a9-9d9b0b5edfe7",
   "metadata": {},
   "source": [
    "## The Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39012ba2-ca5b-4391-9b2a-d62d04d2e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self, in_channels, latent_dim=3, dropout_p=0.2, channels=[32, 64, 128], input_shape=(203, 514)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.channels = channels\n",
    "\n",
    "        encoder_layers = []\n",
    "        prev_channels = in_channels\n",
    "        h, w = input_shape\n",
    "\n",
    "        for ch in channels:\n",
    "            encoder_layers += [\n",
    "                nn.Conv2d(prev_channels, ch, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(ch),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout2d(p=dropout_p),\n",
    "            ]\n",
    "            prev_channels = ch\n",
    "            h = math.floor((h + 2 * 1 - 3) / 2 + 1)  # Conv2d output size formula\n",
    "            w = math.floor((w + 2 * 1 - 3) / 2 + 1)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.unflatten_shape = (channels[-1], h, w)\n",
    "\n",
    "        flat_dim = channels[-1] * h * w\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_enc = nn.Sequential(\n",
    "            nn.Linear(flat_dim, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(64, latent_dim)\n",
    "        )\n",
    "        self.fc_dec = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(64, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(1024, flat_dim)\n",
    "        )\n",
    "\n",
    "        decoder_layers = []\n",
    "        rev_channels = list(reversed(channels))\n",
    "        for i in range(len(rev_channels) - 1):\n",
    "            decoder_layers += [\n",
    "                nn.ConvTranspose2d(rev_channels[i], rev_channels[i + 1], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(rev_channels[i + 1]),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout2d(p=dropout_p),\n",
    "            ]\n",
    "\n",
    "        decoder_layers += [\n",
    "            nn.ConvTranspose2d(rev_channels[-1], in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        ]\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            x = x * mask\n",
    "        x = self.encoder(x)\n",
    "        z = self.fc_enc(self.flatten(x))\n",
    "        x = self.fc_dec(z)\n",
    "        x = x.view(x.size(0), *self.unflatten_shape)\n",
    "        x = self.decoder(x)\n",
    "        return x[:, :, :self.input_shape[0], :self.input_shape[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fca60a-dc9b-4276-b7d2-b0dec85f4b07",
   "metadata": {},
   "source": [
    "## Reconstructing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cba5928-7ed3-43a3-81c1-f9e3e2923f86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"/home/jovyan/spatiotemporal-mining-medsea/data/medsea.nc\")\n",
    "\n",
    "X_np, M_np = helper_functions.preprocessing_conv(ds, [\"thetao\", \"so\"], [50, 300, 1000], True, 1)\n",
    "X = torch.tensor(X_np)  # (B, C, H, W)\n",
    "M = torch.tensor(M_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f3f71b-6f4b-4f6d-acd9-2e67cf2293e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CAE(in_channels=X_np.shape[1], latent_dim=3, dropout_p=0.1, channels= [32, 64, 128, 256, 512, 1024]).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/CAE.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee451fc5-beb4-4f9f-b93e-7de9a3d1387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/spatiotemporal-mining-medsea/information_filtering/trend_removal/results/../../helper_functions.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset = TensorDataset(torch.tensor(X, dtype=torch.float32).to(device))\n"
     ]
    }
   ],
   "source": [
    "original_z = helper_functions.preprocessing(ds, [\"thetao\"], [50], \"location\", True, -1)\n",
    "\n",
    "# Getting the mask\n",
    "M_tensor = torch.tensor(M_np[:, :, :203, :514], dtype=torch.float32)\n",
    "M_mask = M_tensor[0].reshape(-1) > 0  # (C * H * W,)\n",
    "\n",
    "# Reconstruction of the stacked z_vector\n",
    "X_recon = helper_functions.reconstruct_in_batches(X, model, device, batch_size=16)\n",
    "flat_recon = helper_functions.reconstruction_to_vector_masked_positions(X_recon, M_mask)\n",
    "coords = original_z.location\n",
    "reconstructed_z = helper_functions.reconstructed_to_stack(ds, \"thetao\", 50, flat_recon, coords)\n",
    "\n",
    "helper_functions.plot_reconstruction_comparison(\n",
    "    z_stack_original=original_z,\n",
    "    z_stack_recon=reconstructed_z,\n",
    "    time_indices=[0, 90, 176, 322],\n",
    "    cmin=-2,\n",
    "    cmax=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f99179-f7b6-455d-94f4-1b358fd67b74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Clustering with K-Means, K=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a73e2-4a76-42ad-b9b3-c151a41a7bf8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = helper_functions.apply_kmeans(flat_recon, 9)\n",
    "labels += 1\n",
    "\n",
    "helper_functions.plot_cluster_timeline(original_z, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee69b3-ca4b-4963-9794-943b244dd317",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"hungarian\"\n",
    "kmeans_series = helper_functions.load_clusterseries(path, \"kmeans_9clusters.npy\")\n",
    "_, permutation = helper_functions.find_best_permutation(kmeans_series, labels, 9)\n",
    "labels = np.array([permutation[k] for k in labels])\n",
    "helper_functions.plot_cluster_timeline(original_z, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a39d4-16d9-4fdc-90d1-247e3dfbfc8c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculating the MSE Loss per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e972e-a7bd-4953-9339-be110aa30227",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "helper_functions.plot_average_loss_map_from_data(original_z, reconstructed_z, labels, 0, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114e47a-bae3-4032-b061-8316a1c13fd3",
   "metadata": {},
   "source": [
    "### Depth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59201d-6fcd-4ca1-b2da-16eb5c527c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = helper_functions.preprocessing(ds, [\"thetao\"], [50], \"location\", True, 1).location\n",
    "recon_temp_50 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 50, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_temp_50, labels, -2, 2)\n",
    "\n",
    "recon_so_50 = helper_functions.reconstructed_to_stack(ds, \"so\", 50, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_so_50, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33092aea-8657-4891-b78f-b988625ef332",
   "metadata": {},
   "source": [
    "### Depth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84525a60-dd18-4334-983b-8a378da7abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = helper_functions.preprocessing(ds, [\"thetao\"], [300], \"location\", True, 1).location\n",
    "recon_temp_300 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 300, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_temp_300, labels, -2, 2)\n",
    "\n",
    "recon_so_300 = helper_functions.reconstructed_to_stack(ds, \"so\", 300, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_so_300, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a9009-4933-4202-9dc1-ac065583b8e3",
   "metadata": {},
   "source": [
    "### Depth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7dbd43-47dd-4c9c-a160-c6533d8d5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = helper_functions.preprocessing(ds, [\"thetao\"], [1000], \"location\", True, 1).location\n",
    "recon_temp_1000 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 1000, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_temp_1000, labels, -2, 2)\n",
    "\n",
    "recon_so_1000 = helper_functions.reconstructed_to_stack(ds, \"so\", 1000, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_so_1000, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f10520-ec8b-4454-9174-7f63f9ef32ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Clustering with K-Means, K=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2246d2-51b6-4e96-8471-b91dffb59be8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = helper_functions.apply_kmeans(flat_recon, 4)\n",
    "labels += 1\n",
    "\n",
    "helper_functions.plot_cluster_timeline(recon_temp_50, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5f899-f593-47df-a8a4-96bc0bc26ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hungarian\"\n",
    "kmeans_series = helper_functions.load_clusterseries(path, \"kmeans_4clusters.npy\")\n",
    "_, permutation = helper_functions.find_best_permutation(kmeans_series, labels, 4)\n",
    "\n",
    "labels = np.array([permutation[k] for k in labels])\n",
    "helper_functions.plot_cluster_timeline(recon_temp_50, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ed760-3760-429f-a834-0b2ec33d9196",
   "metadata": {},
   "source": [
    "### MSE Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7371d-cc54-4c6a-8e13-b5a69855ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.plot_average_loss_map_from_data(original_z, reconstructed_z, labels, 0, 1.5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e107f-ac44-4002-94d9-eb5a6aef6b3d",
   "metadata": {},
   "source": [
    "### Depth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd99db-3514-447d-bd26-4fbea685905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = helper_functions.preprocessing(ds, [\"thetao\"], [50], \"location\", True, 1).location\n",
    "recon_temp_50 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 50, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_temp_50, labels, -2, 2, 2)\n",
    "\n",
    "recon_so_50 = helper_functions.reconstructed_to_stack(ds, \"so\", 50, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_so_50, labels, -2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb65a04-db67-488f-9987-b68299f19e82",
   "metadata": {},
   "source": [
    "### Depth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66d554-ab44-4d2a-b3a6-92a509a20bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = helper_functions.preprocessing(ds, [\"thetao\"], [300], \"location\", True, 1).location\n",
    "recon_temp_300 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 300, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_temp_300, labels, -2, 2, 2)\n",
    "\n",
    "recon_so_300 = helper_functions.reconstructed_to_stack(ds, \"so\", 300, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_so_300, labels, -2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c7036-c7de-478f-a9a3-f25e090049c7",
   "metadata": {},
   "source": [
    "### Depth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0761d09-1778-4df4-a0ee-8f6f06ffc00b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = helper_functions.preprocessing(ds, [\"thetao\"], [1000], \"location\", True, 1).location\n",
    "recon_temp_1000 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 1000, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_temp_1000, labels, -2, 2, 2)\n",
    "\n",
    "recon_so_1000 = helper_functions.reconstructed_to_stack(ds, \"so\", 1000, flat_recon, coords)\n",
    "helper_functions.plot_average_cluster(recon_so_1000, labels, -2, 2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
