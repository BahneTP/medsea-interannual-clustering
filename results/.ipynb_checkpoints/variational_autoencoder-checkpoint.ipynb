{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4951ac0e-4f7b-4c6d-87e8-fa212d1750a9",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "This notebook makes use of the **Autoencoder**, which is used to reduce the dimensionality of our dataset in a non-linear way. Furthermore, we then apply **k-means Clustering** as in our last notebook in our new created **Latent Space** in lower dimension. We do so, to get rid of less important variables and achieve a better Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2f90b1-6826-4a2b-896b-f0f59aa9999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cartopy xarray matplotlib netCDF4 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3c815e-a7d9-46d6-a45d-c64b8ed20a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_functions' from '/home/jovyan/spatiotemporal-mining-medsea/notebooks/helper_functions.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helper_functions\n",
    "import importlib\n",
    "from ipywidgets import FloatSlider\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from ipywidgets import interact, IntSlider\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "importlib.reload(helper_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2175a-a4a6-4443-89a4-c30147743c2e",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c45eb1-fe33-437d-bb7b-91c8b1a76a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20554.545012 MB\n",
      "(342, 170424)\n",
      "466.280064 MB\n",
      "170424\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(\"/home/jovyan/spatiotemporal-mining-medsea/data/medsea.nc\")\n",
    "print(ds.nbytes / 1e6, \"MB\")\n",
    "\n",
    "z_temp = helper_functions.preprocessing(ds, [\"thetao\", \"so\"], [50, 300, 1000], \"location\")\n",
    "print(z_temp.shape)\n",
    "X = z_temp.values\n",
    "input_dimension = X.shape[1]\n",
    "print(z_temp.nbytes / 1e6, \"MB\")\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11779e19-1403-4924-b480-f5457daaee2e",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36cff7de-fbe6-4edb-9c94-5fead6c7a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=27)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train)), batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test)), batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed51ed5-9af0-42ad-a1a9-9d9b0b5edfe7",
   "metadata": {},
   "source": [
    "## The Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33015db9-48a7-4147-b637-ca509c39ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        # Shared encoder backbone\n",
    "        self.encoder_shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        # Separate layers for mean and log-variance\n",
    "        self.mu_layer = nn.Linear(256, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(256, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, input_dim)\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder_shared(x)\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f29428-7c81-4a80-a415-c051c92d86cd",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "439fbcc1-fb73-464f-b771-4b94041ff2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_recon, x, mu, logvar, beta=1e-3):\n",
    "    recon_loss = F.mse_loss(x_recon, x, reduction='mean')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    total_loss = recon_loss + beta * kl_div\n",
    "    return total_loss, recon_loss.item(), kl_div.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f426540-b690-433f-9359-a00113b5a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(epoch, total_epochs, max_beta=1):\n",
    "    return max_beta * (epoch / total_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3135c56e-a342-4273-a344-db6ccb56a33e",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8b3e058-34ba-439d-aeda-aa0a21e6dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs: int, kl_beta=1e-3, kl_beta_max=1):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        kl_beta = get_beta(epoch, num_epochs, kl_beta_max) if kl_beta == -1 else kl_beta\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            x = batch[0].to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            loss, recon, kl = vae_loss(x_recon, x, mu, logvar, beta=kl_beta)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * x.size(0)\n",
    "    \n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "    \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x = batch[0].to(device).float()\n",
    "                x_recon, mu, logvar = model(x)\n",
    "                loss, recon, kl = vae_loss(x_recon, x, mu, logvar, beta=kl_beta)\n",
    "\n",
    "                running_val_loss += loss.item() * x.size(0)\n",
    "    \n",
    "        val_loss = running_val_loss / len(test_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Recon: {recon:.4f} | KL: {kl:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c2819-ad9d-4ea5-96fc-1e5b6767a919",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c5c9d9-3fee-4276-892e-9456e006205c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using device: cuda\n",
      "Trainierbare Parameter: 174,953,662\n",
      "Epoch 1/50 | Train Loss: 1.1732 | Val Loss: 1.0442 | Recon: 1.0442 | KL: 11.8331\n",
      "Epoch 2/50 | Train Loss: 1.1525 | Val Loss: 1.0069 | Recon: 1.0069 | KL: 5.9433\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainierbare Parameter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 12\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkl_beta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkl_beta_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#1e-3\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, kl_beta, kl_beta_max)\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m running_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Training using device: {device}')\n",
    "\n",
    "model = VariationalAutoencoder(input_dim=input_dimension, latent_dim=3).float().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainierbare Parameter: {total_params:,}\")\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses, val_losses = train(num_epochs,kl_beta=-1, kl_beta_max=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68549efe-8ccf-4412-a9e6-0868f92d4e68",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eeb7ee-74d4-4189-bd3a-3e642670e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d21eb-5ce1-4f2e-906c-fcebde37cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "latents_mu = []\n",
    "latents_logvar = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[0].to(device).float()\n",
    "        _, mu, logvar = model(x)\n",
    "        latents_mu.append(mu.cpu())\n",
    "        latents_logvar.append(logvar.cpu())\n",
    "\n",
    "# Alles zusammenfügen\n",
    "mu_all = torch.cat(latents_mu, dim=0)           # shape: (n_samples, latent_dim)\n",
    "logvar_all = torch.cat(latents_logvar, dim=0)   # shape: (n_samples, latent_dim)\n",
    "\n",
    "# Statistiken\n",
    "mu_std = mu_all.std(dim=0)\n",
    "logvar_mean = logvar_all.mean(dim=0)\n",
    "logvar_std = logvar_all.std(dim=0)\n",
    "\n",
    "# Ausgabe\n",
    "print(\"Std of mu per latent dim:\")\n",
    "print(mu_std)\n",
    "\n",
    "print(\"\\nMean of logvar per latent dim:\")\n",
    "print(logvar_mean)\n",
    "\n",
    "print(\"\\nStd of logvar per latent dim:\")\n",
    "print(logvar_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01e22b-7072-4a87-b201-21b998e0e6d1",
   "metadata": {},
   "source": [
    "## Reconstructing single samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737804eb-ada0-4173-951b-71d671f8ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(helper_functions)\n",
    "X_recon_all = helper_functions.reconstruct_in_batches(X, model, device, 64)\n",
    "\n",
    "original_z = helper_functions.preprocessing(ds, [\"thetao\"], [50], \"location\")\n",
    "reconstructed_z = helper_functions.reconstructed_to_stack(ds, \"thetao\", 50, X_recon_all)\n",
    "\n",
    "helper_functions.plot_reconstruction_comparison(\n",
    "    z_stack_original=original_z,\n",
    "    z_stack_recon=reconstructed_z,\n",
    "    time_indices=[0, 15, 80, 190],\n",
    "    cmin=-2,\n",
    "    cmax=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f99179-f7b6-455d-94f4-1b358fd67b74",
   "metadata": {},
   "source": [
    "## Clustering with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fa6b4-85e4-46e3-be6a-37327cbd0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "\n",
    "def get_latents_and_cluster(model, X, n_clusters=5, batch_size=512, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Computes the latent representations (mu) for all inputs and clusters them using KMeans.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained VariationalAutoencoder\n",
    "    - X: Input data as a numpy array or torch.Tensor of shape (n_samples, input_dim)\n",
    "    - n_clusters: Number of clusters for KMeans\n",
    "    - batch_size: Batch size for efficient computation\n",
    "    - device: Device to run the model on (\"cpu\" or \"cuda\")\n",
    "\n",
    "    Returns:\n",
    "    - latents: Tensor of shape (n_samples, latent_dim)\n",
    "    - cluster_labels: Numpy array of shape (n_samples,) with cluster assignments\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        X_tensor = X\n",
    "    else:\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    X_tensor = X_tensor.to(device)\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_tensor), batch_size):\n",
    "            batch = X_tensor[i:i+batch_size]\n",
    "            h = model.encoder_shared(batch)\n",
    "            mu = model.mu_layer(h)\n",
    "            latents.append(mu.cpu())\n",
    "\n",
    "    latents = torch.cat(latents, dim=0)  # (n_samples, latent_dim)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(latents.numpy())\n",
    "\n",
    "    return latents, cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedd128-90ff-4067-b68b-fbf76397bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents, labels= get_latents_and_cluster(model, X, n_clusters = 9, batch_size=16)\n",
    "labels+=1\n",
    "helper_functions.plot_cluster_timeline(z_temp, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a164d-acaa-4c79-baae-eed654eaa66b",
   "metadata": {},
   "source": [
    "### Depth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d17114-c79f-41b0-be9c-d5ee555056c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_temp_50 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 50, X_recon_all)\n",
    "helper_functions.plot_average_cluster(recon_temp_50, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af822d-b2a5-4db0-ac47-9856f3101de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_so_50 = helper_functions.reconstructed_to_stack(ds, \"so\", 50, X_recon_all)\n",
    "helper_functions.plot_average_cluster(recon_so_50, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eecd56-147a-4747-b8fa-fbc07afdbd4d",
   "metadata": {},
   "source": [
    "### Depth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a55c3-1516-4ce9-a6bb-a7fefc72c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_temp_300 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 300, X_recon_all)\n",
    "helper_functions.plot_average_cluster(recon_temp_300, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47800c2c-947e-4c1d-9587-ea6cc1931d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_so_300 = helper_functions.reconstructed_to_stack(ds, \"so\", 300, X_recon_all)\n",
    "helper_functions.plot_average_cluster(recon_so_300, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03024947-50b7-4828-8c69-1d03a1060fff",
   "metadata": {},
   "source": [
    "### Depth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c77b6-c983-4d72-89cb-79a88bfb51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_temp_1000 = helper_functions.reconstructed_to_stack(ds, \"thetao\", 300, X_recon_all)\n",
    "helper_functions.plot_average_cluster(recon_temp_50, labels, -2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6092d-a696-4284-bd3a-ed1352a43d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_so_1000 = helper_functions.reconstructed_to_stack(ds, \"so\", 1000, X_recon_all)\n",
    "helper_functions.plot_average_cluster(recon_so_1000, labels, -2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
